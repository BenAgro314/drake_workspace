{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PandaStation import (\n",
    "    PandaStation, FindResource, AddPackagePaths, AddRgbdSensors, draw_points, draw_open3d_point_cloud, \n",
    "    create_open3d_point_cloud, AddShape)\n",
    "#from PandaGrasping import *\n",
    "\n",
    "\n",
    "# Start a single meshcat server instance to use for the remainder of this notebook.\n",
    "from meshcat.servers.zmqserver import start_zmq_server_as_subprocess\n",
    "proc, zmq_url, web_url = start_zmq_server_as_subprocess(server_args=[])\n",
    "\n",
    "# Let's do all of our imports here, too.\n",
    "import numpy as np\n",
    "import ipywidgets\n",
    "import pydot\n",
    "import pydrake.all\n",
    "import os\n",
    "from IPython.display import display, SVG\n",
    "import open3d as o3d\n",
    "import meshcat\n",
    "import meshcat.geometry as g\n",
    "import meshcat.transformations as tf\n",
    "\n",
    "\n",
    "import pydrake.all\n",
    "from pydrake.geometry import Cylinder, Box\n",
    "from pydrake.all import (\n",
    "    RigidTransform, RotationMatrix, AngleAxis, RollPitchYaw, InverseKinematics, MultibodyPlant, Parser,\n",
    "    FindResourceOrThrow, Solve, PiecewisePolynomial, TrajectorySource, SceneGraph, DiagramBuilder,\n",
    "    AddMultibodyPlantSceneGraph, LinearBushingRollPitchYaw, MathematicalProgram, AutoDiffXd, GenerateHtml, Role,\n",
    "    MakeRenderEngineVtk, DepthRenderCamera, RenderCameraCore, CameraInfo, ClippingRange,  DepthImageToPointCloud,\n",
    "    BaseField, RenderEngineVtkParams, ConnectMeshcatVisualizer, DepthRange, RgbdSensor, MeshcatPointCloudVisualizer,\n",
    "    LoadModelDirectives, ProcessModelDirectives, GeometrySet\n",
    "    )\n",
    "from PandaInverseKinematics import PandaInverseKinematics, PandaIKTraj, Waypoint, Trajectory\n",
    "from RRT import PandaRRTPlanner, PandaRRTompl\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grasp_candidate_cost(X_G, plant_context, cloud, plant, scene_graph, scene_graph_context):\n",
    "    \n",
    "    body = plant.GetBodyByName(\"panda_hand\")\n",
    "\n",
    "    X_GW = X_G.inverse()\n",
    "    pts = np.asarray(cloud.points).T\n",
    "    p_GC = X_GW.multiply(pts)\n",
    "\n",
    "    # Crop to a region inside of the finger box.\n",
    "    crop_min = [-0.009, -0.035, 0.06]\n",
    "    crop_max = [0.009, 0.035, 0.115]\n",
    "    indices = np.all((crop_min[0] <= p_GC[0,:], p_GC[0,:] <= crop_max[0],\n",
    "                      crop_min[1] <= p_GC[1,:], p_GC[1,:] <= crop_max[1],\n",
    "                      crop_min[2] <= p_GC[2,:], p_GC[2,:] <= crop_max[2]), \n",
    "                     axis=0)\n",
    "\n",
    "\n",
    "    query_object = scene_graph.get_query_output_port().Eval(scene_graph_context)\n",
    "    collision_pairs = query_object.ComputePointPairPenetration()\n",
    "    \n",
    "    # check collisions with objects in the world \n",
    "    if query_object.HasCollisions():\n",
    "        #print('collision with world')\n",
    "        return np.inf\n",
    "\n",
    "    # Check collisions between the gripper and the point cloud\n",
    "    margin = 0.0  # must be smaller than the margin used in the point cloud preprocessing.\n",
    "    for pt in cloud.points:\n",
    "        distances = query_object.ComputeSignedDistanceToPoint(pt, threshold=margin)\n",
    "        if distances:\n",
    "            #print('collision with point cloud')\n",
    "            return np.inf\n",
    "\n",
    "    n_GC = X_GW.rotation().multiply(np.asarray(cloud.normals)[indices,:].T)\n",
    "\n",
    "    # Penalize deviation of the gripper from vertical.\n",
    "    # weight * -dot([0, 0, -1], R_G * [0, 1, 0]) = weight * R_G[2,1]\n",
    "    cost = 20.0*X_G.rotation().matrix()[2, 1]\n",
    "\n",
    "    # Reward sum |dot product of normals with gripper x|^2\n",
    "    cost -= np.sum(n_GC[0,:]**2)\n",
    "\n",
    "    return cost\n",
    "\n",
    "def process_bin_point_cloud(diagram, context, cameras, bin_name):\n",
    "\n",
    "    plant = diagram.GetSubsystemByName(\"plant\")\n",
    "    plant_context = plant.GetMyContextFromRoot(context)\n",
    "\n",
    "    # Compute crop box.\n",
    "    bin_instance = plant.GetModelInstanceByName(bin_name)\n",
    "    bin_body = plant.GetBodyByName(\"bin_base\", bin_instance)\n",
    "    X_B = plant.EvalBodyPoseInWorld(plant_context, bin_body)\n",
    "    margin = 0.001  # only because simulation is perfect!\n",
    "    a = X_B.multiply([-.22+0.025+margin, -.29+0.025+margin, 0.015+margin])\n",
    "    b = X_B.multiply([.22-0.1-margin, .29-0.025-margin, 2.0])\n",
    "    crop_min = np.minimum(a,b)\n",
    "    crop_max = np.maximum(a,b)\n",
    "\n",
    "    # Evaluate the camera output ports to get the images.\n",
    "    merged_pcd = o3d.geometry.PointCloud()\n",
    "    for c in cameras:\n",
    "        point_cloud = diagram.GetOutputPort(f\"{c}_point_cloud\").Eval(context)\n",
    "        pcd = create_open3d_point_cloud(point_cloud)\n",
    "\n",
    "        # Crop to region of interest.\n",
    "        pcd = pcd.crop(\n",
    "            o3d.geometry.AxisAlignedBoundingBox(min_bound=crop_min,\n",
    "                                                max_bound=crop_max))    \n",
    "\n",
    "        pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(\n",
    "            radius=0.1, max_nn=30))\n",
    "\n",
    "        camera = plant.GetModelInstanceByName(c)\n",
    "        body = plant.GetBodyByName(\"base\", camera)\n",
    "        X_C = plant.EvalBodyPoseInWorld(plant_context, body)\n",
    "        pcd.orient_normals_towards_camera_location(X_C.translation())\n",
    "        \n",
    "        # Merge point clouds.\n",
    "        merged_pcd += pcd\n",
    "\n",
    "    # Voxelize down-sample.  (Note that the normals still look reasonable)\n",
    "    return merged_pcd.voxel_down_sample(voxel_size=0.005)\n",
    "\n",
    "\n",
    "\n",
    "def generate_grasp_candidate_antipodal(plant_context, cloud, plant, scene_graph, scene_graph_context, panda, rng, meshcat=None, avoid_names = None):\n",
    "    \"\"\"\n",
    "    Picks a random point in the cloud, and aligns the robot finger with the normal of that pixel. \n",
    "    The rotation around the normal axis is drawn from a uniform distribution over [min_roll, max_roll].\n",
    "    \"\"\"\n",
    "    body = plant.GetBodyByName(\"panda_hand\")\n",
    "\n",
    "    index = rng.integers(0,len(cloud.points)-1)\n",
    "\n",
    "    # Use S for sample point/frame.\n",
    "    p_WS = np.asarray(cloud.points[index])\n",
    "    n_WS = np.asarray(cloud.normals[index])\n",
    "\n",
    "    if meshcat:\n",
    "        vertices = np.empty((3,2))\n",
    "        vertices[:, 0] = p_WS\n",
    "        vertices[:, 1] = p_WS + 0.05*n_WS\n",
    "        meshcat.set_object(g.LineSegments(g.PointsGeometry(vertices),\n",
    "                            g.MeshBasicMaterial(color=0xff0000)))\n",
    "  \n",
    "\n",
    "    if not np.isclose(np.linalg.norm(n_WS), 1.0):\n",
    "        return np.inf, None\n",
    "\n",
    "    Gy = n_WS # gripper y axis aligns with normal\n",
    "    # make orthonormal z axis, aligned with world down\n",
    "    z = np.array([0.0, 0.0, -1.0])\n",
    "    if np.abs(np.dot(z,Gy)) < 1e-6:\n",
    "        # normal was pointing straight down.  reject this sample.\n",
    "        #print('here')\n",
    "        return np.inf, None\n",
    "\n",
    "    Gz = z - np.dot(z,Gy)*Gy\n",
    "    Gx = np.cross(Gy, Gz)\n",
    "    R_WG = RotationMatrix(np.vstack((Gx, Gy, Gz)).T)\n",
    "    p_GS_G = [0, 0.035, 0.11]\n",
    "\n",
    "    # Try orientations from the center out\n",
    "    min_pitch=-np.pi/3.0\n",
    "    max_pitch=np.pi/3.0\n",
    "    alpha = np.array([0.5, 0.65, 0.35, 0.8, 0.2, 1.0, 0.0])\n",
    "    thetas = [0]\n",
    "    for theta in thetas:#(min_pitch + (max_pitch - min_pitch)*alpha):\n",
    "        # Rotate the object in the hand by a random rotation (around the normal).\n",
    "        R_WG2 = R_WG.multiply(RotationMatrix.MakeYRotation(theta))\n",
    "\n",
    "        # Use G for gripper frame.\n",
    "        p_SG_W = - R_WG2.multiply(p_GS_G)\n",
    "        p_WG = p_WS + p_SG_W \n",
    "\n",
    "        X_G = RigidTransform(R_WG2, p_WG)\n",
    "        ik = PandaInverseKinematics(plant, plant_context, panda, avoid_names = avoid_names)\n",
    "        p_WQ = X_G.translation()\n",
    "        tol = np.ones(3)*0.01\n",
    "        q_nominal = np.array([ 0., 0.55, 0., -1.45, 0., 1.58, 0.]) \n",
    "        ik.AddPositionConstraint(p_WQ+tol, p_WQ+tol)\n",
    "        ik.AddOrientationConstraint(X_G.rotation(), 0.01)\n",
    "        ik.AddMinDistanceConstraint(0.01)\n",
    "        prog = ik.get_prog()\n",
    "        q = ik.get_q()\n",
    "        prog.AddQuadraticErrorCost(np.identity(len(q)), q_nominal, q)\n",
    "        prog.SetInitialGuess(q, q_nominal)\n",
    "        result = Solve(prog)\n",
    "\n",
    "        if not result.is_success():\n",
    "            continue\n",
    "        \n",
    "        q = result.GetSolution(q)\n",
    "        plant.SetPositions(plant_context, panda, q)\n",
    "        plant.SetPositions(plant_context, plant.GetModelInstanceByName(\"hand\"), [-0.04, 0.04])\n",
    "        #print('evaluating cost')\n",
    "        #print(X_G)\n",
    "        cost = grasp_candidate_cost(X_G, plant_context, cloud, plant, scene_graph, scene_graph_context)\n",
    "        #X_G = plant.GetFreeBodyPose(plant_context, body)\n",
    "        if np.isfinite(cost):\n",
    "            return cost, X_G\n",
    "\n",
    "        #draw_grasp_candidate(q)\n",
    "\n",
    "    return np.inf, None\n",
    "\n",
    "def draw_grasp_candidate(q):\n",
    "    builder = DiagramBuilder()\n",
    "    \n",
    "    builder = pydrake.systems.framework.DiagramBuilder()\n",
    "\n",
    "    station = builder.AddSystem(PandaStation())\n",
    "    station.SetupBinStation()\n",
    "\n",
    "    plant = station.get_multibody_plant()\n",
    "    panda = plant.GetModelInstanceByName(\"panda\")\n",
    "\n",
    "    station.Finalize()\n",
    "    \n",
    "\n",
    "    \n",
    "    station_context = station.CreateDefaultContext()\n",
    "    plant_context = plant.GetMyContextFromRoot(station_context)\n",
    "    scene_graph = station.get_scene_graph()\n",
    "    scene_graph_context = station.GetSubsystemContext(scene_graph, station_context)\n",
    "    \n",
    "    \n",
    "\n",
    "    meshcat = pydrake.systems.meshcat_visualizer.ConnectMeshcatVisualizer(builder,\n",
    "          scene_graph,\n",
    "          output_port=station.GetOutputPort(\"query_object\"),\n",
    "          delete_prefix_on_load=True,                                      \n",
    "          zmq_url=zmq_url)\n",
    "    \n",
    "    diagram = builder.Build()\n",
    "    plant.SetPositions(plant_context, panda, q)\n",
    "\n",
    "    meshcat.load()\n",
    "    diagram.Publish(context)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_environment_model(bin_name=\"bin0\"):\n",
    "    # Make one model of the environment, but the robot only gets to see the sensor outputs.\n",
    "    \n",
    "    directive = FindResource(\"models/two_bins_w_cameras.yaml\")\n",
    "\n",
    "    builder = DiagramBuilder()\n",
    "    plant, scene_graph = AddMultibodyPlantSceneGraph(builder, time_step=0.0005)\n",
    "    parser = Parser(plant)\n",
    "    AddPackagePaths(parser)\n",
    "    ProcessModelDirectives(LoadModelDirectives(directive), plant, parser)\n",
    "\n",
    "    brick = parser.AddModelFromFile(FindResourceOrThrow(\"drake/examples/manipulation_station/models/061_foam_brick.sdf\"), 'brick')\n",
    "    plant.WeldFrames(plant.world_frame(), plant.GetFrameByName('base_link', brick), RigidTransform(RotationMatrix.MakeZRotation(np.pi/2.0 +np.random.uniform(-0.1, 0.1)), [-.1+np.random.uniform(-0.1, 0.1), -.65, 0.09]))\n",
    "    \n",
    "    plant.Finalize()\n",
    "    AddRgbdSensors(builder, plant, scene_graph)\n",
    "\n",
    "    \n",
    "    meshcat = ConnectMeshcatVisualizer(builder, scene_graph, zmq_url=zmq_url, prefix=\"environment\")\n",
    "\n",
    "    diagram = builder.Build()\n",
    "    context = diagram.CreateDefaultContext()\n",
    "    plant_context = plant.GetMyContextFromRoot(context)\n",
    "    scene_graph_context = scene_graph.GetMyContextFromRoot(context)\n",
    "\n",
    "    return diagram, context, plant, plant_context, scene_graph, scene_graph_context\n",
    "\n",
    "def fix_collisions(plant, scene_graph, scene_graph_context):\n",
    "    \n",
    "    query_object = scene_graph.get_query_output_port().Eval(scene_graph_context)\n",
    "    collision_pairs = query_object.ComputePointPairPenetration()\n",
    "    \n",
    "    for pair in collision_pairs:\n",
    "        sA = GeometrySet([pair.id_A])\n",
    "        sB = GeometrySet([pair.id_B])\n",
    "        scene_graph.ExcludeCollisionsBetween(scene_graph_context, sA, sB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to meshcat-server at zmq_url=tcp://127.0.0.1:6025...\n",
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7025/static/\n",
      "Connected to meshcat-server.\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n"
     ]
    }
   ],
   "source": [
    "environment, environment_context, env_plant, env_plant_context, env_scene_graph, env_scene_graph_context = make_environment_model()\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "builder = pydrake.systems.framework.DiagramBuilder()\n",
    "\n",
    "station = builder.AddSystem(PandaStation())\n",
    "station.SetupBinStation()\n",
    "\n",
    "plant = station.get_multibody_plant()\n",
    "panda = plant.GetModelInstanceByName(\"panda\")\n",
    "c1 = AddShape(plant, Cylinder(0.03, 1), \"c1\")\n",
    "plant.WeldFrames(plant.world_frame(), plant.GetFrameByName(\"c1\", c1), RigidTransform([0.15, -0.25, 0.5])) # add a model to test collisions\n",
    "c2 = AddShape(plant, Cylinder(0.03, 1), \"c2\")\n",
    "plant.WeldFrames(plant.world_frame(), plant.GetFrameByName(\"c2\", c2), RigidTransform([-0.3, 0, 0.5])) # add a model to test collisions\n",
    "\n",
    "\n",
    "station.Finalize()\n",
    "\n",
    "station_context = station.CreateDefaultContext()\n",
    "plant_context = plant.GetMyContextFromRoot(station_context)\n",
    "scene_graph = station.get_scene_graph()\n",
    "scene_graph_context = station.GetSubsystemContext(scene_graph, station_context)\n",
    "start_pose = plant.EvalBodyPoseInWorld(plant_context, plant.GetBodyByName(\"panda_hand\"))\n",
    "\n",
    "\n",
    "cloud = process_bin_point_cloud(environment, environment_context, [\"camera0\", \"camera1\", \"camera2\"], \"bin0\")\n",
    "\n",
    "avoid_names= ['bin0', 'bin1', 'c1', 'c2']\n",
    "\n",
    "costs = []\n",
    "X_Gs = []\n",
    "fix_collisions(plant, scene_graph, scene_graph_context)\n",
    "for i in range(100):\n",
    "    cost, X_G = generate_grasp_candidate_antipodal(plant_context, cloud, plant, scene_graph, scene_graph_context, panda, rng, avoid_names = avoid_names)#, meshcat=v.vis[\"sample\"])\n",
    "    print(cost)\n",
    "    if np.isfinite(cost):      \n",
    "        costs.append(cost)\n",
    "        X_Gs.append(X_G)\n",
    "        break\n",
    "\n",
    "indices = np.asarray(costs).argsort()[:1]\n",
    "print(X_Gs[indices[0]])\n",
    "\n",
    "start_pose = plant.EvalBodyPoseInWorld(plant_context, plant.GetBodyByName(\"panda_hand\"))\n",
    "\n",
    "\n",
    "trajectory = None\n",
    "\n",
    "\n",
    "print(\"starting rrt\")\n",
    "rrt = PandaRRTompl(plant, scene_graph, plant_context, scene_graph_context, panda,\n",
    "                        start_pose, 0, X_Gs[indices[0]], 10, avoid_names)\n",
    "print(\"done rrt\")\n",
    "\n",
    "trajectory = rrt.get_trajectory()\n",
    "\n",
    "q_traj_system = builder.AddSystem(TrajectorySource(trajectory))\n",
    "\n",
    "meshcat = pydrake.systems.meshcat_visualizer.ConnectMeshcatVisualizer(builder,\n",
    "          scene_graph,\n",
    "          output_port=station.GetOutputPort(\"query_object\"),\n",
    "          delete_prefix_on_load=True,                                      \n",
    "          zmq_url=zmq_url)#, role = Role.kProximity)# <- this commented part allows visualization of the collisions\n",
    "\n",
    "draw_open3d_point_cloud(meshcat.vis[\"cloud\"], cloud, size=0.003)\n",
    "\n",
    "builder.Connect(q_traj_system.get_output_port(),\n",
    "                  station.GetInputPort(\"panda_position\"))\n",
    "\n",
    "\n",
    "\n",
    "diagram = builder.Build()\n",
    "\n",
    "simulator = pydrake.systems.analysis.Simulator(diagram)\n",
    "station_context = station.GetMyContextFromRoot(simulator.get_mutable_context())\n",
    "station.GetInputPort(\"hand_position\").FixValue(station_context, [0.08]) # taking the desired hand separation\n",
    "\n",
    "meshcat.start_recording()\n",
    "\n",
    "simulator.AdvanceTo(10)\n",
    "\n",
    "meshcat.stop_recording()\n",
    "meshcat.publish_recording()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drake_env",
   "language": "python",
   "name": "drake_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
